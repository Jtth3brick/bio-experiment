{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0d22181",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcbba541",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Copy the read database over. This will now store the results so we will rename it\n",
    "!cp ../read_db.sqlite3 bio.sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26356143",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split -> Run Count:\n",
      "  Split 1: 319 runs\n",
      "  Split 2: 315 runs\n",
      "  Split 3: 312 runs\n",
      "  Split 4: 307 runs\n",
      "  Split 5: 194 runs\n"
     ]
    }
   ],
   "source": [
    "# Read split data\n",
    "split_dir = \"../experiment_train/split_data\"\n",
    "split_runs = []\n",
    "splits = set()\n",
    "\n",
    "for split_fn in sorted(os.listdir(split_dir)):\n",
    "    if not split_fn.startswith(\"split_\"):\n",
    "        continue\n",
    "    filepath = f\"{split_dir}/{split_fn}\"\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        split_data = pickle.load(f)\n",
    "\n",
    "    # Collect all runs from train/val/cv sets\n",
    "    runs = set()\n",
    "    if split_data.X_train is not None:\n",
    "        runs.update(split_data.X_train.index)\n",
    "\n",
    "    # We only did CV, so this isn't needed:\n",
    "    # if split_data.X_val is not None:\n",
    "    #     runs.update(split_data.X_val.index)\n",
    "\n",
    "    if split_data.X_cv is not None:\n",
    "        runs.update(split_data.X_cv.index)\n",
    "\n",
    "    for run in runs:\n",
    "        split_runs.append((split_data.split_id, run))\n",
    "\n",
    "    splits.add(split_data.split_id)\n",
    "\n",
    "# Create Conn\n",
    "conn = sqlite3.connect(\"bio.sqlite3\")\n",
    "conn.execute(\"PRAGMA foreign_keys = ON\")\n",
    "\n",
    "# Create splits table\n",
    "conn.execute(\"DROP TABLE IF EXISTS splits\")\n",
    "conn.execute(\n",
    "    \"\"\"\n",
    "      CREATE TABLE IF NOT EXISTS splits (\n",
    "        split_id TEXT PRIMARY KEY\n",
    "      )\n",
    "  \"\"\"\n",
    ")\n",
    "conn.executemany(\"INSERT OR IGNORE INTO splits VALUES (?)\", [(i,) for i in splits])\n",
    "\n",
    "# Create split_runs table\n",
    "conn.execute(\"DROP TABLE IF EXISTS split_runs\")\n",
    "conn.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE split_runs (\n",
    "        split_id TEXT NOT NULL,\n",
    "        run TEXT NOT NULL,\n",
    "        PRIMARY KEY (split_id, run),\n",
    "        FOREIGN KEY (run) REFERENCES runs(run)\n",
    "        FOREIGN KEY (split_id) REFERENCES splits(split_id)\n",
    "\n",
    "    )\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "conn.executemany(\"INSERT INTO split_runs VALUES (?, ?)\", split_runs)\n",
    "conn.commit()\n",
    "\n",
    "# Verify\n",
    "print(\"Split -> Run Count:\")\n",
    "for split_id, count in conn.execute(\n",
    "    \"SELECT split_id, COUNT(*) FROM split_runs GROUP BY split_id ORDER BY split_id\"\n",
    "):\n",
    "    print(f\"  Split {split_id}: {count} runs\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09fe9424",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['config_hash', 'split_id', 'pipeline_name', 'cv_mean', 'cv_std', 'cv_fold_0', 'cv_fold_1', 'cv_fold_2', 'cv_fold_3', 'cv_fold_4', 'hp_steps', 'hp_transform_input', 'hp_verbose', 'hp_Preselection', 'hp_Normalization', 'hp_Model']\n",
      "train_results.shape=(246986, 121)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config_hash</th>\n",
       "      <th>split_id</th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>cv_mean</th>\n",
       "      <th>cv_std</th>\n",
       "      <th>cv_fold_0</th>\n",
       "      <th>cv_fold_1</th>\n",
       "      <th>cv_fold_2</th>\n",
       "      <th>cv_fold_3</th>\n",
       "      <th>cv_fold_4</th>\n",
       "      <th>...</th>\n",
       "      <th>hp_Model__monotonic_cst</th>\n",
       "      <th>hp_Model__oob_score</th>\n",
       "      <th>hp_Model__break_ties</th>\n",
       "      <th>hp_Model__cache_size</th>\n",
       "      <th>hp_Model__coef0</th>\n",
       "      <th>hp_Model__decision_function_shape</th>\n",
       "      <th>hp_Model__degree</th>\n",
       "      <th>hp_Model__kernel</th>\n",
       "      <th>hp_Model__probability</th>\n",
       "      <th>hp_Model__shrinking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b6d02eaee5c5d68d29f3a33bee03b2433906963c310d57...</td>\n",
       "      <td>3</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.927425</td>\n",
       "      <td>0.031961</td>\n",
       "      <td>0.959402</td>\n",
       "      <td>0.939103</td>\n",
       "      <td>0.883772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a5693e81ef838fa9459036f1744aa64cc2f078a07671ea...</td>\n",
       "      <td>3</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.927425</td>\n",
       "      <td>0.031961</td>\n",
       "      <td>0.959402</td>\n",
       "      <td>0.939103</td>\n",
       "      <td>0.883772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50ad34c4b4e96125530928d3aebf8f00f9385225296f1a...</td>\n",
       "      <td>3</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.927425</td>\n",
       "      <td>0.031961</td>\n",
       "      <td>0.959402</td>\n",
       "      <td>0.939103</td>\n",
       "      <td>0.883772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ab33ab45e7c26dbbdb2d1ceafb5854ebd6ceea52bc2e29...</td>\n",
       "      <td>3</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.927425</td>\n",
       "      <td>0.031961</td>\n",
       "      <td>0.959402</td>\n",
       "      <td>0.939103</td>\n",
       "      <td>0.883772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ef2f8d2a83c651e6141f3a0d057885d7bd8fc1c331c772...</td>\n",
       "      <td>3</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.926816</td>\n",
       "      <td>0.016560</td>\n",
       "      <td>0.943376</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         config_hash  split_id pipeline_name  \\\n",
       "0  b6d02eaee5c5d68d29f3a33bee03b2433906963c310d57...         3           xgb   \n",
       "1  a5693e81ef838fa9459036f1744aa64cc2f078a07671ea...         3           xgb   \n",
       "2  50ad34c4b4e96125530928d3aebf8f00f9385225296f1a...         3           xgb   \n",
       "3  ab33ab45e7c26dbbdb2d1ceafb5854ebd6ceea52bc2e29...         3           xgb   \n",
       "4  ef2f8d2a83c651e6141f3a0d057885d7bd8fc1c331c772...         3           xgb   \n",
       "\n",
       "    cv_mean    cv_std  cv_fold_0  cv_fold_1  cv_fold_2  cv_fold_3  cv_fold_4  \\\n",
       "0  0.927425  0.031961   0.959402   0.939103   0.883772        NaN        NaN   \n",
       "1  0.927425  0.031961   0.959402   0.939103   0.883772        NaN        NaN   \n",
       "2  0.927425  0.031961   0.959402   0.939103   0.883772        NaN        NaN   \n",
       "3  0.927425  0.031961   0.959402   0.939103   0.883772        NaN        NaN   \n",
       "4  0.926816  0.016560   0.943376   0.910256        NaN        NaN        NaN   \n",
       "\n",
       "   ... hp_Model__monotonic_cst  hp_Model__oob_score  hp_Model__break_ties  \\\n",
       "0  ...                     NaN                  NaN                   NaN   \n",
       "1  ...                     NaN                  NaN                   NaN   \n",
       "2  ...                     NaN                  NaN                   NaN   \n",
       "3  ...                     NaN                  NaN                   NaN   \n",
       "4  ...                     NaN                  NaN                   NaN   \n",
       "\n",
       "  hp_Model__cache_size hp_Model__coef0 hp_Model__decision_function_shape  \\\n",
       "0                  NaN             NaN                               NaN   \n",
       "1                  NaN             NaN                               NaN   \n",
       "2                  NaN             NaN                               NaN   \n",
       "3                  NaN             NaN                               NaN   \n",
       "4                  NaN             NaN                               NaN   \n",
       "\n",
       "   hp_Model__degree hp_Model__kernel hp_Model__probability hp_Model__shrinking  \n",
       "0               NaN              NaN                   NaN                 NaN  \n",
       "1               NaN              NaN                   NaN                 NaN  \n",
       "2               NaN              NaN                   NaN                 NaN  \n",
       "3               NaN              NaN                   NaN                 NaN  \n",
       "4               NaN              NaN                   NaN                 NaN  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the train results (to add to the database)\n",
    "train_results = pd.read_csv(\"../experiment_train/results.csv\", low_memory=False)\n",
    "\n",
    "# Drop misleading (all NaN) column\n",
    "train_results.drop(columns=[\"validate_score\"], inplace=True)\n",
    "\n",
    "# Print subset of columns we may be using\n",
    "print([c for c in train_results.columns if \"__\" not in c])\n",
    "\n",
    "print(f\"{train_results.shape=}\")\n",
    "\n",
    "train_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f6fbde3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create connection\n",
    "conn = sqlite3.connect(\"bio.sqlite3\")\n",
    "conn.execute(\"PRAGMA foreign_keys = ON\")\n",
    "\n",
    "# Add train results to the database\n",
    "train_results.to_sql(\"train_results\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Create a view that selects the top 5 models per (pipeline_name, split) grouping\n",
    "conn.execute(\n",
    "    \"\"\"\n",
    "    CREATE VIEW IF NOT EXISTS top_models AS\n",
    "    SELECT *\n",
    "    FROM (\n",
    "        SELECT *,\n",
    "               ROW_NUMBER() OVER (\n",
    "                   PARTITION BY pipeline_name, split_id \n",
    "                   ORDER BY cv_mean DESC\n",
    "               ) as rank\n",
    "        FROM train_results\n",
    "    )\n",
    "    WHERE rank <= 5\n",
    "\"\"\"\n",
    ")\n",
    "conn.commit()\n",
    "\n",
    "# Close the Connection\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv-train",
   "language": "python",
   "name": "uv-train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
